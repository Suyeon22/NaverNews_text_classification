{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DBOW_model = doc2vec.Doc2Vec.load('DBOW_model3.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "with open('test.txt', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "tagged_train = [TaggedDocument(d, [c]) for d, c in train]\n",
    "tagged_test = [TaggedDocument(d, [c]) for d, c in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. 모델 테스트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류를 위해 tagged_train과 tagged_test의 words와 tags를 나눠줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [DBOW_model.infer_vector(doc.words) for doc in tagged_train]\n",
    "y_train = [doc.tags[0] for doc in tagged_train]\n",
    "len(X_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [DBOW_model.infer_vector(doc.words) for doc in tagged_test]\n",
    "y_test = [doc.tags[0] for doc in tagged_test]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeling = y_train+y_test\n",
    "labeling_np = np.asarray(labeling, dtype=str)\n",
    "\n",
    "a , b = np.unique(labeling_np, return_inverse=True ) # 0~7755\n",
    "c , d = np.unique(labeling_np[7756:], return_counts=True )\n",
    "\n",
    "train_label_np=a[b][:7756]\n",
    "test_label_np=a[b][7756:]\n",
    "\n",
    "y_train_np=b[:7756].astype(int)\n",
    "y_test_np=b[7756:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '3', '2', ..., '2', '2', '5'], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 6\n",
    "y_train_np = np.eye(nb_classes)[y_train_np]\n",
    "y_test_np = np.eye(nb_classes)[y_test_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with MLP : [해당 자료 참고](https://gitlab.com/agilesoda/Word2Vec/blob/master/03_Word2Vec_Gensim.ipynb)하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hufs/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/hufs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout, variance_scaling_initializer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "keep_prob = 0.5\n",
    "He = variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7756, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 100])\n",
    "Y = tf.placeholder(tf.float32, [None, 6])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected]):\n",
    "    \n",
    "    hidden_layer1 = fully_connected(X, 512, scope=\"h1\", weights_initializer=He)\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer2 = fully_connected(h1_drop, 512, scope=\"h2\", weights_initializer=He)\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer3 = fully_connected(h2_drop, 1024, scope=\"h3\", weights_initializer=He)\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer4 = fully_connected(h3_drop, 1024, scope=\"h4\", weights_initializer=He)\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hypothesis = fully_connected(h4_drop, 6, activation_fn=None, scope=\"hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "\n",
    "# AdamOptimizer 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"train_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy)\n",
    "\n",
    "with tf.name_scope(\"test_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_acc\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# summary 노드 : 모든 요약 데이터를 실행하는 단일 연산(op)으로 결합\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# 마지막으로 이 요약 데이터를 save하기 위해 tf.summary.FileWriter로 전달한다.\n",
    "writer = tf.summary.FileWriter(\"./logs/DBOW3\")\n",
    "\n",
    "# Show the graph\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> command 창에서 다음을 입력하고 tensorboard를 실행한다\n",
    "*  tensorboard --logdir=./logs/naver_classificaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    0][Train: 0.69758][Test: 0.79639][2018-01-29 16:13:33]\n",
      "[Epoch:    1][Train: 0.86834][Test: 0.84536][2018-01-29 16:13:36]\n",
      "[Epoch:    2][Train: 0.90215][Test: 0.86082][2018-01-29 16:13:39]\n",
      "[Epoch:    3][Train: 0.91691][Test: 0.86392][2018-01-29 16:13:42]\n",
      "[Epoch:    4][Train: 0.92416][Test: 0.86186][2018-01-29 16:13:44]\n",
      "[Epoch:    5][Train: 0.93037][Test: 0.86804][2018-01-29 16:13:48]\n",
      "[Epoch:    6][Train: 0.93566][Test: 0.86856][2018-01-29 16:13:51]\n",
      "[Epoch:    7][Train: 0.94178][Test: 0.86804][2018-01-29 16:13:54]\n",
      "[Epoch:    8][Train: 0.94521][Test: 0.86495][2018-01-29 16:13:57]\n",
      "[Epoch:    9][Train: 0.94751][Test: 0.86907][2018-01-29 16:14:00]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_acc = 0\n",
    "    total_batch = int(len(X_train_np) / batch_size)\n",
    "\n",
    "    for i in range(0, len(X_train_np), batch_size):\n",
    "        batch_xs = X_train_np[i:i+batch_size]\n",
    "        batch_ys = y_train_np[i:i+batch_size]\n",
    "        \n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_acc = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        acc = sess.run(train_accuracy, feed_dict=feed_dict_acc)\n",
    "        avg_acc += acc / total_batch\n",
    "        \n",
    "    test_feed_dict = {X: X_test_np, Y: y_test_np, train_mode: False}\n",
    "    summary, test_acc = sess.run([merged_summary, test_accuracy], feed_dict=test_feed_dict)\n",
    "    writer.add_summary(summary, global_step=epoch)      \n",
    "        \n",
    "#     if epoch % 10 == 0:\n",
    "    time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"[Epoch: {:>4}][Train: {:>.5f}][Test: {:>.5f}][{}]\".format(epoch, avg_acc, test_acc, time))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1)), tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(hypothesis,tf.argmax(Y, 1), k=2), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.94751 \n",
      " Test Accuracy: 0.86907 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {:>.5f} \\n Test Accuracy: {:>.5f} \\n\".format(avg_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 6])\n",
    "y_pred = tf.placeholder(tf.float32, [None, 6])\n",
    "y_true_cls = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.305,0.5,'True')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEmCAYAAAAjsVjMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng9bMLDMHrZlZZv8PDKX+7i9vsDgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa12afef860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_true = b[7756:]\n",
    "cls_pred = sess.run(tf.argmax(hypothesis, 1), feed_dict=test_feed_dict)\n",
    "cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)        \n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(6)\n",
    "plt.xticks(tick_marks, range(6))\n",
    "plt.yticks(tick_marks, range(6))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Accuracy: 0.91022] 0\n",
      "[Accuracy: 0.84830] 1\n",
      "[Accuracy: 0.75926] 2\n",
      "[Accuracy: 0.86378] 3\n",
      "[Accuracy: 0.89783] 4\n",
      "[Accuracy: 0.93519] 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(\"[Accuracy: {:>.5f}] {}\".format(cm[i][i] / d[i], c[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
