{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DBOW_model = doc2vec.Doc2Vec.load('DBOW_model5.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "with open('test.txt', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "tagged_train = [TaggedDocument(d, [c]) for d, c in train]\n",
    "tagged_test = [TaggedDocument(d, [c]) for d, c in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. 모델 테스트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류를 위해 tagged_train과 tagged_test의 words와 tags를 나눠줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [DBOW_model.infer_vector(doc.words) for doc in tagged_train]\n",
    "y_train = [doc.tags[0] for doc in tagged_train]\n",
    "len(X_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [DBOW_model.infer_vector(doc.words) for doc in tagged_test]\n",
    "y_test = [doc.tags[0] for doc in tagged_test]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeling = y_train+y_test\n",
    "labeling_np = np.asarray(labeling, dtype=str)\n",
    "\n",
    "a , b = np.unique(labeling_np, return_inverse=True ) # 0~7755\n",
    "c , d = np.unique(labeling_np[7756:], return_counts=True )\n",
    "\n",
    "train_label_np=a[b][:7756]\n",
    "test_label_np=a[b][7756:]\n",
    "\n",
    "y_train_np=b[:7756].astype(int)\n",
    "y_test_np=b[7756:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '3', '2', ..., '2', '2', '5'], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 6\n",
    "y_train_np = np.eye(nb_classes)[y_train_np]\n",
    "y_test_np = np.eye(nb_classes)[y_test_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with MLP : [해당 자료 참고](https://gitlab.com/agilesoda/Word2Vec/blob/master/03_Word2Vec_Gensim.ipynb)하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hufs/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/hufs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout, variance_scaling_initializer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "keep_prob = 0.5\n",
    "He = variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7756, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 300])\n",
    "Y = tf.placeholder(tf.float32, [None, 6])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected]):\n",
    "    \n",
    "    hidden_layer1 = fully_connected(X, 512, scope=\"h1\", weights_initializer=He)\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer2 = fully_connected(h1_drop, 512, scope=\"h2\", weights_initializer=He)\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer3 = fully_connected(h2_drop, 1024, scope=\"h3\", weights_initializer=He)\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer4 = fully_connected(h3_drop, 1024, scope=\"h4\", weights_initializer=He)\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hypothesis = fully_connected(h4_drop, 6, activation_fn=None, scope=\"hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "\n",
    "# AdamOptimizer 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"train_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy)\n",
    "\n",
    "with tf.name_scope(\"test_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_acc\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# summary 노드 : 모든 요약 데이터를 실행하는 단일 연산(op)으로 결합\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# 마지막으로 이 요약 데이터를 save하기 위해 tf.summary.FileWriter로 전달한다.\n",
    "writer = tf.summary.FileWriter(\"./logs/DBOW5\")\n",
    "\n",
    "# Show the graph\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> command 창에서 다음을 입력하고 tensorboard를 실행한다\n",
    "*  tensorboard --logdir=./logs/naver_classificaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    0][Train: 0.64741][Test: 0.77938][2018-01-29 16:15:43]\n",
      "[Epoch:    1][Train: 0.89703][Test: 0.85155][2018-01-29 16:15:46]\n",
      "[Epoch:    2][Train: 0.93875][Test: 0.86134][2018-01-29 16:15:52]\n",
      "[Epoch:    3][Train: 0.95868][Test: 0.86598][2018-01-29 16:15:57]\n",
      "[Epoch:    4][Train: 0.96835][Test: 0.86340][2018-01-29 16:16:02]\n",
      "[Epoch:    5][Train: 0.97778][Test: 0.86907][2018-01-29 16:16:07]\n",
      "[Epoch:    6][Train: 0.98276][Test: 0.86237][2018-01-29 16:16:12]\n",
      "[Epoch:    7][Train: 0.98871][Test: 0.86289][2018-01-29 16:16:18]\n",
      "[Epoch:    8][Train: 0.99323][Test: 0.85619][2018-01-29 16:16:27]\n",
      "[Epoch:    9][Train: 0.99561][Test: 0.86340][2018-01-29 16:16:33]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_acc = 0\n",
    "    total_batch = int(len(X_train_np) / batch_size)\n",
    "\n",
    "    for i in range(0, len(X_train_np), batch_size):\n",
    "        batch_xs = X_train_np[i:i+batch_size]\n",
    "        batch_ys = y_train_np[i:i+batch_size]\n",
    "        \n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_acc = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        acc = sess.run(train_accuracy, feed_dict=feed_dict_acc)\n",
    "        avg_acc += acc / total_batch\n",
    "        \n",
    "    test_feed_dict = {X: X_test_np, Y: y_test_np, train_mode: False}\n",
    "    summary, test_acc = sess.run([merged_summary, test_accuracy], feed_dict=test_feed_dict)\n",
    "    writer.add_summary(summary, global_step=epoch)      \n",
    "        \n",
    "#     if epoch % 10 == 0:\n",
    "    time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"[Epoch: {:>4}][Train: {:>.5f}][Test: {:>.5f}][{}]\".format(epoch, avg_acc, test_acc, time))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1)), tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(hypothesis,tf.argmax(Y, 1), k=2), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.99561 \n",
      " Test Accuracy: 0.86340 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {:>.5f} \\n Test Accuracy: {:>.5f} \\n\".format(avg_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 6])\n",
    "y_pred = tf.placeholder(tf.float32, [None, 6])\n",
    "y_true_cls = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.305,0.5,'True')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEmCAYAAAAjsVjMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJakxg1aSGjNoJakxg1aSGvv/eYaSOl8NYv4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f2c03a860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_true = b[7756:]\n",
    "cls_pred = sess.run(tf.argmax(hypothesis, 1), feed_dict=test_feed_dict)\n",
    "cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)        \n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(6)\n",
    "plt.xticks(tick_marks, range(6))\n",
    "plt.yticks(tick_marks, range(6))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Accuracy: 0.91022] 0\n",
      "[Accuracy: 0.83282] 1\n",
      "[Accuracy: 0.78086] 2\n",
      "[Accuracy: 0.83901] 3\n",
      "[Accuracy: 0.90093] 4\n",
      "[Accuracy: 0.91667] 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(\"[Accuracy: {:>.5f}] {}\".format(cm[i][i] / d[i], c[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
