{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DBOW_model = doc2vec.Doc2Vec.load('DBOW_model2.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "with open('test.txt', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "tagged_train = [TaggedDocument(d, [c]) for d, c in train]\n",
    "tagged_test = [TaggedDocument(d, [c]) for d, c in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. 모델 테스트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류를 위해 tagged_train과 tagged_test의 words와 tags를 나눠줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [DBOW_model.infer_vector(doc.words) for doc in tagged_train]\n",
    "y_train = [doc.tags[0] for doc in tagged_train]\n",
    "len(X_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [DBOW_model.infer_vector(doc.words) for doc in tagged_test]\n",
    "y_test = [doc.tags[0] for doc in tagged_test]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeling = y_train+y_test\n",
    "labeling_np = np.asarray(labeling, dtype=str)\n",
    "\n",
    "a , b = np.unique(labeling_np, return_inverse=True ) # 0~7755\n",
    "c , d = np.unique(labeling_np[7756:], return_counts=True )\n",
    "\n",
    "train_label_np=a[b][:7756]\n",
    "test_label_np=a[b][7756:]\n",
    "\n",
    "y_train_np=b[:7756].astype(int)\n",
    "y_test_np=b[7756:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '3', '2', ..., '2', '2', '5'], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 6\n",
    "y_train_np = np.eye(nb_classes)[y_train_np]\n",
    "y_test_np = np.eye(nb_classes)[y_test_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with MLP : [해당 자료 참고](https://gitlab.com/agilesoda/Word2Vec/blob/master/03_Word2Vec_Gensim.ipynb)하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hufs/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/hufs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout, variance_scaling_initializer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "keep_prob = 0.5\n",
    "He = variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7756, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 100])\n",
    "Y = tf.placeholder(tf.float32, [None, 6])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected]):\n",
    "    \n",
    "    hidden_layer1 = fully_connected(X, 512, scope=\"h1\", weights_initializer=He)\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer2 = fully_connected(h1_drop, 512, scope=\"h2\", weights_initializer=He)\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer3 = fully_connected(h2_drop, 1024, scope=\"h3\", weights_initializer=He)\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer4 = fully_connected(h3_drop, 1024, scope=\"h4\", weights_initializer=He)\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hypothesis = fully_connected(h4_drop, 6, activation_fn=None, scope=\"hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "\n",
    "# AdamOptimizer 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"train_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy)\n",
    "\n",
    "with tf.name_scope(\"test_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_acc\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# summary 노드 : 모든 요약 데이터를 실행하는 단일 연산(op)으로 결합\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# 마지막으로 이 요약 데이터를 save하기 위해 tf.summary.FileWriter로 전달한다.\n",
    "writer = tf.summary.FileWriter(\"./logs/DBOW2\")\n",
    "\n",
    "# Show the graph\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> command 창에서 다음을 입력하고 tensorboard를 실행한다\n",
    "*  tensorboard --logdir=./logs/naver_classificaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    0][Train: 0.69915][Test: 0.79278][2018-01-29 16:11:47]\n",
      "[Epoch:    1][Train: 0.88900][Test: 0.85619][2018-01-29 16:11:49]\n",
      "[Epoch:    2][Train: 0.92325][Test: 0.86546][2018-01-29 16:11:52]\n",
      "[Epoch:    3][Train: 0.93618][Test: 0.86392][2018-01-29 16:11:55]\n",
      "[Epoch:    4][Train: 0.94296][Test: 0.87526][2018-01-29 16:11:57]\n",
      "[Epoch:    5][Train: 0.94938][Test: 0.87268][2018-01-29 16:12:00]\n",
      "[Epoch:    6][Train: 0.95277][Test: 0.87680][2018-01-29 16:12:02]\n",
      "[Epoch:    7][Train: 0.95720][Test: 0.87629][2018-01-29 16:12:05]\n",
      "[Epoch:    8][Train: 0.96110][Test: 0.87680][2018-01-29 16:12:07]\n",
      "[Epoch:    9][Train: 0.96649][Test: 0.87887][2018-01-29 16:12:10]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_acc = 0\n",
    "    total_batch = int(len(X_train_np) / batch_size)\n",
    "\n",
    "    for i in range(0, len(X_train_np), batch_size):\n",
    "        batch_xs = X_train_np[i:i+batch_size]\n",
    "        batch_ys = y_train_np[i:i+batch_size]\n",
    "        \n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_acc = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        acc = sess.run(train_accuracy, feed_dict=feed_dict_acc)\n",
    "        avg_acc += acc / total_batch\n",
    "        \n",
    "    test_feed_dict = {X: X_test_np, Y: y_test_np, train_mode: False}\n",
    "    summary, test_acc = sess.run([merged_summary, test_accuracy], feed_dict=test_feed_dict)\n",
    "    writer.add_summary(summary, global_step=epoch)      \n",
    "        \n",
    "#     if epoch % 10 == 0:\n",
    "    time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"[Epoch: {:>4}][Train: {:>.5f}][Test: {:>.5f}][{}]\".format(epoch, avg_acc, test_acc, time))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1)), tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(hypothesis,tf.argmax(Y, 1), k=2), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.96649 \n",
      " Test Accuracy: 0.87887 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {:>.5f} \\n Test Accuracy: {:>.5f} \\n\".format(avg_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 6])\n",
    "y_pred = tf.placeholder(tf.float32, [None, 6])\n",
    "y_true_cls = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.305,0.5,'True')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEmCAYAAAAjsVjMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzEFrZpbZ/wOqn/CVpilr5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee116a2d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_true = b[7756:]\n",
    "cls_pred = sess.run(tf.argmax(hypothesis, 1), feed_dict=test_feed_dict)\n",
    "cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)        \n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(6)\n",
    "plt.xticks(tick_marks, range(6))\n",
    "plt.yticks(tick_marks, range(6))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Accuracy: 0.91022] 0\n",
      "[Accuracy: 0.85139] 1\n",
      "[Accuracy: 0.77160] 2\n",
      "[Accuracy: 0.87616] 3\n",
      "[Accuracy: 0.91022] 4\n",
      "[Accuracy: 0.95370] 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(\"[Accuracy: {:>.5f}] {}\".format(cm[i][i] / d[i], c[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
