{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DM_model = doc2vec.Doc2Vec.load('DM_model3.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "with open('test.txt', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "tagged_train = [TaggedDocument(d, [c]) for d, c in train]\n",
    "tagged_test = [TaggedDocument(d, [c]) for d, c in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. 모델 테스트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류를 위해 tagged_train과 tagged_test의 words와 tags를 나눠줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [DM_model.infer_vector(doc.words) for doc in tagged_train]\n",
    "y_train = [doc.tags[0] for doc in tagged_train]\n",
    "len(X_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [DM_model.infer_vector(doc.words) for doc in tagged_test]\n",
    "y_test = [doc.tags[0] for doc in tagged_test]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeling = y_train+y_test\n",
    "labeling_np = np.asarray(labeling, dtype=str)\n",
    "\n",
    "a , b = np.unique(labeling_np, return_inverse=True ) # 0~7755\n",
    "c , d = np.unique(labeling_np[7756:], return_counts=True )\n",
    "\n",
    "train_label_np=a[b][:7756]\n",
    "test_label_np=a[b][7756:]\n",
    "\n",
    "y_train_np=b[:7756].astype(int)\n",
    "y_test_np=b[7756:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '3', '2', ..., '2', '2', '5'], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 6\n",
    "y_train_np = np.eye(nb_classes)[y_train_np]\n",
    "y_test_np = np.eye(nb_classes)[y_test_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with MLP : [해당 자료 참고](https://gitlab.com/agilesoda/Word2Vec/blob/master/03_Word2Vec_Gensim.ipynb)하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hufs/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/hufs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout, variance_scaling_initializer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "keep_prob = 0.5\n",
    "He = variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7756, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 100])\n",
    "Y = tf.placeholder(tf.float32, [None, 6])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected]):\n",
    "    \n",
    "    hidden_layer1 = fully_connected(X, 512, scope=\"h1\", weights_initializer=He)\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer2 = fully_connected(h1_drop, 512, scope=\"h2\", weights_initializer=He)\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer3 = fully_connected(h2_drop, 1024, scope=\"h3\", weights_initializer=He)\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer4 = fully_connected(h3_drop, 1024, scope=\"h4\", weights_initializer=He)\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hypothesis = fully_connected(h4_drop, 6, activation_fn=None, scope=\"hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "\n",
    "# AdamOptimizer 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"train_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy)\n",
    "\n",
    "with tf.name_scope(\"test_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_acc\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# summary 노드 : 모든 요약 데이터를 실행하는 단일 연산(op)으로 결합\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# 마지막으로 이 요약 데이터를 save하기 위해 tf.summary.FileWriter로 전달한다.\n",
    "writer = tf.summary.FileWriter(\"./logs/DM3\")\n",
    "\n",
    "# Show the graph\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> command 창에서 다음을 입력하고 tensorboard를 실행한다\n",
    "*  tensorboard --logdir=./logs/naver_classificaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    0][Train: 0.73947][Test: 0.73557][2018-01-29 16:19:33]\n",
      "[Epoch:    1][Train: 0.88766][Test: 0.76443][2018-01-29 16:19:36]\n",
      "[Epoch:    2][Train: 0.91153][Test: 0.77577][2018-01-29 16:19:39]\n",
      "[Epoch:    3][Train: 0.92451][Test: 0.77629][2018-01-29 16:19:41]\n",
      "[Epoch:    4][Train: 0.92799][Test: 0.77062][2018-01-29 16:19:45]\n",
      "[Epoch:    5][Train: 0.93363][Test: 0.78247][2018-01-29 16:19:48]\n",
      "[Epoch:    6][Train: 0.93936][Test: 0.78247][2018-01-29 16:19:51]\n",
      "[Epoch:    7][Train: 0.94183][Test: 0.78660][2018-01-29 16:19:54]\n",
      "[Epoch:    8][Train: 0.94578][Test: 0.78711][2018-01-29 16:19:57]\n",
      "[Epoch:    9][Train: 0.95051][Test: 0.78454][2018-01-29 16:20:02]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_acc = 0\n",
    "    total_batch = int(len(X_train_np) / batch_size)\n",
    "\n",
    "    for i in range(0, len(X_train_np), batch_size):\n",
    "        batch_xs = X_train_np[i:i+batch_size]\n",
    "        batch_ys = y_train_np[i:i+batch_size]\n",
    "        \n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_acc = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        acc = sess.run(train_accuracy, feed_dict=feed_dict_acc)\n",
    "        avg_acc += acc / total_batch\n",
    "        \n",
    "    test_feed_dict = {X: X_test_np, Y: y_test_np, train_mode: False}\n",
    "    summary, test_acc = sess.run([merged_summary, test_accuracy], feed_dict=test_feed_dict)\n",
    "    writer.add_summary(summary, global_step=epoch)      \n",
    "        \n",
    "#     if epoch % 10 == 0:\n",
    "    time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"[Epoch: {:>4}][Train: {:>.5f}][Test: {:>.5f}][{}]\".format(epoch, avg_acc, test_acc, time))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1)), tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(hypothesis,tf.argmax(Y, 1), k=2), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.95051 \n",
      " Test Accuracy: 0.78454 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {:>.5f} \\n Test Accuracy: {:>.5f} \\n\".format(avg_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 6])\n",
    "y_pred = tf.placeholder(tf.float32, [None, 6])\n",
    "y_true_cls = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.305,0.5,'True')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEmCAYAAAAjsVjMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f98d804c828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_true = b[7756:]\n",
    "cls_pred = sess.run(tf.argmax(hypothesis, 1), feed_dict=test_feed_dict)\n",
    "cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)        \n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(6)\n",
    "plt.xticks(tick_marks, range(6))\n",
    "plt.yticks(tick_marks, range(6))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Accuracy: 0.81424] 0\n",
      "[Accuracy: 0.81115] 1\n",
      "[Accuracy: 0.73457] 2\n",
      "[Accuracy: 0.69040] 3\n",
      "[Accuracy: 0.81115] 4\n",
      "[Accuracy: 0.84568] 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(\"[Accuracy: {:>.5f}] {}\".format(cm[i][i] / d[i], c[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
