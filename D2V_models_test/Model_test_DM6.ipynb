{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DM_model = doc2vec.Doc2Vec.load('DM_model6.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "with open('test.txt', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "tagged_train = [TaggedDocument(d, [c]) for d, c in train]\n",
    "tagged_test = [TaggedDocument(d, [c]) for d, c in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. 모델 테스트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류를 위해 tagged_train과 tagged_test의 words와 tags를 나눠줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [DM_model.infer_vector(doc.words) for doc in tagged_train]\n",
    "y_train = [doc.tags[0] for doc in tagged_train]\n",
    "len(X_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [DM_model.infer_vector(doc.words) for doc in tagged_test]\n",
    "y_test = [doc.tags[0] for doc in tagged_test]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeling = y_train+y_test\n",
    "labeling_np = np.asarray(labeling, dtype=str)\n",
    "\n",
    "a , b = np.unique(labeling_np, return_inverse=True ) # 0~7755\n",
    "c , d = np.unique(labeling_np[7756:], return_counts=True )\n",
    "\n",
    "train_label_np=a[b][:7756]\n",
    "test_label_np=a[b][7756:]\n",
    "\n",
    "y_train_np=b[:7756].astype(int)\n",
    "y_test_np=b[7756:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '3', '2', ..., '2', '2', '5'], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 6\n",
    "y_train_np = np.eye(nb_classes)[y_train_np]\n",
    "y_test_np = np.eye(nb_classes)[y_test_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with MLP : [해당 자료 참고](https://gitlab.com/agilesoda/Word2Vec/blob/master/03_Word2Vec_Gensim.ipynb)하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hufs/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/hufs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout, variance_scaling_initializer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "keep_prob = 0.5\n",
    "He = variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7756, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 300])\n",
    "Y = tf.placeholder(tf.float32, [None, 6])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected]):\n",
    "    \n",
    "    hidden_layer1 = fully_connected(X, 512, scope=\"h1\", weights_initializer=He)\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer2 = fully_connected(h1_drop, 512, scope=\"h2\", weights_initializer=He)\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer3 = fully_connected(h2_drop, 1024, scope=\"h3\", weights_initializer=He)\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer4 = fully_connected(h3_drop, 1024, scope=\"h4\", weights_initializer=He)\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hypothesis = fully_connected(h4_drop, 6, activation_fn=None, scope=\"hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "\n",
    "# AdamOptimizer 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"train_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy)\n",
    "\n",
    "with tf.name_scope(\"test_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_acc\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# summary 노드 : 모든 요약 데이터를 실행하는 단일 연산(op)으로 결합\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# 마지막으로 이 요약 데이터를 save하기 위해 tf.summary.FileWriter로 전달한다.\n",
    "writer = tf.summary.FileWriter(\"./logs/DM6\")\n",
    "\n",
    "# Show the graph\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> command 창에서 다음을 입력하고 tensorboard를 실행한다\n",
    "*  tensorboard --logdir=./logs/naver_classificaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    0][Train: 0.77976][Test: 0.76753][2018-01-29 16:21:26]\n",
      "[Epoch:    1][Train: 0.91717][Test: 0.77887][2018-01-29 16:21:29]\n",
      "[Epoch:    2][Train: 0.93137][Test: 0.78041][2018-01-29 16:21:31]\n",
      "[Epoch:    3][Train: 0.93350][Test: 0.79124][2018-01-29 16:21:34]\n",
      "[Epoch:    4][Train: 0.93710][Test: 0.78918][2018-01-29 16:21:37]\n",
      "[Epoch:    5][Train: 0.94431][Test: 0.79485][2018-01-29 16:21:40]\n",
      "[Epoch:    6][Train: 0.94869][Test: 0.78711][2018-01-29 16:21:42]\n",
      "[Epoch:    7][Train: 0.95056][Test: 0.79742][2018-01-29 16:21:45]\n",
      "[Epoch:    8][Train: 0.95156][Test: 0.79072][2018-01-29 16:21:47]\n",
      "[Epoch:    9][Train: 0.95321][Test: 0.79948][2018-01-29 16:21:50]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_acc = 0\n",
    "    total_batch = int(len(X_train_np) / batch_size)\n",
    "\n",
    "    for i in range(0, len(X_train_np), batch_size):\n",
    "        batch_xs = X_train_np[i:i+batch_size]\n",
    "        batch_ys = y_train_np[i:i+batch_size]\n",
    "        \n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_acc = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        acc = sess.run(train_accuracy, feed_dict=feed_dict_acc)\n",
    "        avg_acc += acc / total_batch\n",
    "        \n",
    "    test_feed_dict = {X: X_test_np, Y: y_test_np, train_mode: False}\n",
    "    summary, test_acc = sess.run([merged_summary, test_accuracy], feed_dict=test_feed_dict)\n",
    "    writer.add_summary(summary, global_step=epoch)      \n",
    "        \n",
    "#     if epoch % 10 == 0:\n",
    "    time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"[Epoch: {:>4}][Train: {:>.5f}][Test: {:>.5f}][{}]\".format(epoch, avg_acc, test_acc, time))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1)), tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(hypothesis,tf.argmax(Y, 1), k=2), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.95321 \n",
      " Test Accuracy: 0.79948 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {:>.5f} \\n Test Accuracy: {:>.5f} \\n\".format(avg_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 6])\n",
    "y_pred = tf.placeholder(tf.float32, [None, 6])\n",
    "y_true_cls = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.305,0.5,'True')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEmCAYAAAAjsVjMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPwNWNVgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feafd40f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_true = b[7756:]\n",
    "cls_pred = sess.run(tf.argmax(hypothesis, 1), feed_dict=test_feed_dict)\n",
    "cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)        \n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(6)\n",
    "plt.xticks(tick_marks, range(6))\n",
    "plt.yticks(tick_marks, range(6))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Accuracy: 0.84211] 0\n",
      "[Accuracy: 0.80805] 1\n",
      "[Accuracy: 0.71914] 2\n",
      "[Accuracy: 0.70898] 3\n",
      "[Accuracy: 0.82353] 4\n",
      "[Accuracy: 0.89506] 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(\"[Accuracy: {:>.5f}] {}\".format(cm[i][i] / d[i], c[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
