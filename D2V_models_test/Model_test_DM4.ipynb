{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DM_model = doc2vec.Doc2Vec.load('DM_model4.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "with open('test.txt', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "tagged_train = [TaggedDocument(d, [c]) for d, c in train]\n",
    "tagged_test = [TaggedDocument(d, [c]) for d, c in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. 모델 테스트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류를 위해 tagged_train과 tagged_test의 words와 tags를 나눠줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [DM_model.infer_vector(doc.words) for doc in tagged_train]\n",
    "y_train = [doc.tags[0] for doc in tagged_train]\n",
    "len(X_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [DM_model.infer_vector(doc.words) for doc in tagged_test]\n",
    "y_test = [doc.tags[0] for doc in tagged_test]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeling = y_train+y_test\n",
    "labeling_np = np.asarray(labeling, dtype=str)\n",
    "\n",
    "a , b = np.unique(labeling_np, return_inverse=True ) # 0~7755\n",
    "c , d = np.unique(labeling_np[7756:], return_counts=True )\n",
    "\n",
    "train_label_np=a[b][:7756]\n",
    "test_label_np=a[b][7756:]\n",
    "\n",
    "y_train_np=b[:7756].astype(int)\n",
    "y_test_np=b[7756:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '3', '2', ..., '2', '2', '5'], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 6\n",
    "y_train_np = np.eye(nb_classes)[y_train_np]\n",
    "y_test_np = np.eye(nb_classes)[y_test_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with MLP : [해당 자료 참고](https://gitlab.com/agilesoda/Word2Vec/blob/master/03_Word2Vec_Gensim.ipynb)하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hufs/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/hufs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout, variance_scaling_initializer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "keep_prob = 0.5\n",
    "He = variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7756, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 300])\n",
    "Y = tf.placeholder(tf.float32, [None, 6])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected]):\n",
    "    \n",
    "    hidden_layer1 = fully_connected(X, 512, scope=\"h1\", weights_initializer=He)\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer2 = fully_connected(h1_drop, 512, scope=\"h2\", weights_initializer=He)\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer3 = fully_connected(h2_drop, 1024, scope=\"h3\", weights_initializer=He)\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer4 = fully_connected(h3_drop, 1024, scope=\"h4\", weights_initializer=He)\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hypothesis = fully_connected(h4_drop, 6, activation_fn=None, scope=\"hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "\n",
    "# AdamOptimizer 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"train_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy)\n",
    "\n",
    "with tf.name_scope(\"test_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_acc\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# summary 노드 : 모든 요약 데이터를 실행하는 단일 연산(op)으로 결합\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# 마지막으로 이 요약 데이터를 save하기 위해 tf.summary.FileWriter로 전달한다.\n",
    "writer = tf.summary.FileWriter(\"./logs/DM4\")\n",
    "\n",
    "# Show the graph\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> command 창에서 다음을 입력하고 tensorboard를 실행한다\n",
    "*  tensorboard --logdir=./logs/naver_classificaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    0][Train: 0.90898][Test: 0.82835][2018-01-29 16:20:01]\n",
      "[Epoch:    1][Train: 0.95624][Test: 0.83454][2018-01-29 16:20:04]\n",
      "[Epoch:    2][Train: 0.95963][Test: 0.84485][2018-01-29 16:20:07]\n",
      "[Epoch:    3][Train: 0.96063][Test: 0.83402][2018-01-29 16:20:10]\n",
      "[Epoch:    4][Train: 0.96223][Test: 0.83763][2018-01-29 16:20:13]\n",
      "[Epoch:    5][Train: 0.96375][Test: 0.83660][2018-01-29 16:20:15]\n",
      "[Epoch:    6][Train: 0.96397][Test: 0.82835][2018-01-29 16:20:18]\n",
      "[Epoch:    7][Train: 0.96493][Test: 0.83814][2018-01-29 16:20:21]\n",
      "[Epoch:    8][Train: 0.96640][Test: 0.83814][2018-01-29 16:20:25]\n",
      "[Epoch:    9][Train: 0.96818][Test: 0.83454][2018-01-29 16:20:28]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_acc = 0\n",
    "    total_batch = int(len(X_train_np) / batch_size)\n",
    "\n",
    "    for i in range(0, len(X_train_np), batch_size):\n",
    "        batch_xs = X_train_np[i:i+batch_size]\n",
    "        batch_ys = y_train_np[i:i+batch_size]\n",
    "        \n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_acc = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        acc = sess.run(train_accuracy, feed_dict=feed_dict_acc)\n",
    "        avg_acc += acc / total_batch\n",
    "        \n",
    "    test_feed_dict = {X: X_test_np, Y: y_test_np, train_mode: False}\n",
    "    summary, test_acc = sess.run([merged_summary, test_accuracy], feed_dict=test_feed_dict)\n",
    "    writer.add_summary(summary, global_step=epoch)      \n",
    "        \n",
    "#     if epoch % 10 == 0:\n",
    "    time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"[Epoch: {:>4}][Train: {:>.5f}][Test: {:>.5f}][{}]\".format(epoch, avg_acc, test_acc, time))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1)), tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(hypothesis,tf.argmax(Y, 1), k=2), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.96818 \n",
      " Test Accuracy: 0.83454 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {:>.5f} \\n Test Accuracy: {:>.5f} \\n\".format(avg_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 6])\n",
    "y_pred = tf.placeholder(tf.float32, [None, 6])\n",
    "y_true_cls = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.305,0.5,'True')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEmCAYAAAAjsVjMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f58e8900588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_true = b[7756:]\n",
    "cls_pred = sess.run(tf.argmax(hypothesis, 1), feed_dict=test_feed_dict)\n",
    "cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)        \n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(6)\n",
    "plt.xticks(tick_marks, range(6))\n",
    "plt.yticks(tick_marks, range(6))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Accuracy: 0.84520] 0\n",
      "[Accuracy: 0.85139] 1\n",
      "[Accuracy: 0.79012] 2\n",
      "[Accuracy: 0.81424] 3\n",
      "[Accuracy: 0.84520] 4\n",
      "[Accuracy: 0.86111] 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(\"[Accuracy: {:>.5f}] {}\".format(cm[i][i] / d[i], c[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
