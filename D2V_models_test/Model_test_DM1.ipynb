{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DM_model = doc2vec.Doc2Vec.load('DM_model1.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "with open('test.txt', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "tagged_train = [TaggedDocument(d, [c]) for d, c in train]\n",
    "tagged_test = [TaggedDocument(d, [c]) for d, c in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. 모델 테스트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류를 위해 tagged_train과 tagged_test의 words와 tags를 나눠줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [DM_model.infer_vector(doc.words) for doc in tagged_train]\n",
    "y_train = [doc.tags[0] for doc in tagged_train]\n",
    "len(X_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [DM_model.infer_vector(doc.words) for doc in tagged_test]\n",
    "y_test = [doc.tags[0] for doc in tagged_test]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeling = y_train+y_test\n",
    "labeling_np = np.asarray(labeling, dtype=str)\n",
    "\n",
    "a , b = np.unique(labeling_np, return_inverse=True ) # 0~7755\n",
    "c , d = np.unique(labeling_np[7756:], return_counts=True )\n",
    "\n",
    "train_label_np=a[b][:7756]\n",
    "test_label_np=a[b][7756:]\n",
    "\n",
    "y_train_np=b[:7756].astype(int)\n",
    "y_test_np=b[7756:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '3', '2', ..., '2', '2', '5'], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 6\n",
    "y_train_np = np.eye(nb_classes)[y_train_np]\n",
    "y_test_np = np.eye(nb_classes)[y_test_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with MLP : [해당 자료 참고](https://gitlab.com/agilesoda/Word2Vec/blob/master/03_Word2Vec_Gensim.ipynb)하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hufs/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/hufs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout, variance_scaling_initializer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "keep_prob = 0.5\n",
    "He = variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7756, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 100])\n",
    "Y = tf.placeholder(tf.float32, [None, 6])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected]):\n",
    "    \n",
    "    hidden_layer1 = fully_connected(X, 512, scope=\"h1\", weights_initializer=He)\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer2 = fully_connected(h1_drop, 512, scope=\"h2\", weights_initializer=He)\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer3 = fully_connected(h2_drop, 1024, scope=\"h3\", weights_initializer=He)\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer4 = fully_connected(h3_drop, 1024, scope=\"h4\", weights_initializer=He)\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hypothesis = fully_connected(h4_drop, 6, activation_fn=None, scope=\"hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "\n",
    "# AdamOptimizer 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"train_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy)\n",
    "\n",
    "with tf.name_scope(\"test_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_acc\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# summary 노드 : 모든 요약 데이터를 실행하는 단일 연산(op)으로 결합\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# 마지막으로 이 요약 데이터를 save하기 위해 tf.summary.FileWriter로 전달한다.\n",
    "writer = tf.summary.FileWriter(\"./logs/DM1\")\n",
    "\n",
    "# Show the graph\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> command 창에서 다음을 입력하고 tensorboard를 실행한다\n",
    "*  tensorboard --logdir=./logs/naver_classificaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    0][Train: 0.87829][Test: 0.83299][2018-01-29 16:25:44]\n",
      "[Epoch:    1][Train: 0.95251][Test: 0.83196][2018-01-29 16:25:47]\n",
      "[Epoch:    2][Train: 0.95733][Test: 0.83454][2018-01-29 16:25:49]\n",
      "[Epoch:    3][Train: 0.95989][Test: 0.83763][2018-01-29 16:25:52]\n",
      "[Epoch:    4][Train: 0.96058][Test: 0.84175][2018-01-29 16:25:54]\n",
      "[Epoch:    5][Train: 0.96266][Test: 0.83660][2018-01-29 16:25:56]\n",
      "[Epoch:    6][Train: 0.96449][Test: 0.83608][2018-01-29 16:25:59]\n",
      "[Epoch:    7][Train: 0.96449][Test: 0.84175][2018-01-29 16:26:01]\n",
      "[Epoch:    8][Train: 0.96562][Test: 0.84227][2018-01-29 16:26:04]\n",
      "[Epoch:    9][Train: 0.96497][Test: 0.84124][2018-01-29 16:26:06]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_acc = 0\n",
    "    total_batch = int(len(X_train_np) / batch_size)\n",
    "\n",
    "    for i in range(0, len(X_train_np), batch_size):\n",
    "        batch_xs = X_train_np[i:i+batch_size]\n",
    "        batch_ys = y_train_np[i:i+batch_size]\n",
    "        \n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_acc = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        acc = sess.run(train_accuracy, feed_dict=feed_dict_acc)\n",
    "        avg_acc += acc / total_batch\n",
    "        \n",
    "    test_feed_dict = {X: X_test_np, Y: y_test_np, train_mode: False}\n",
    "    summary, test_acc = sess.run([merged_summary, test_accuracy], feed_dict=test_feed_dict)\n",
    "    writer.add_summary(summary, global_step=epoch)      \n",
    "        \n",
    "#     if epoch % 10 == 0:\n",
    "    time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"[Epoch: {:>4}][Train: {:>.5f}][Test: {:>.5f}][{}]\".format(epoch, avg_acc, test_acc, time))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1)), tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(hypothesis,tf.argmax(Y, 1), k=2), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.96497 \n",
      " Test Accuracy: 0.84124\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {:>.5f} \\n Test Accuracy: {:>.5f}\".format(avg_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 6])\n",
    "y_pred = tf.placeholder(tf.float32, [None, 6])\n",
    "y_true_cls = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.305,0.5,'True')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEmCAYAAAAjsVjMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrZlZZg5aM7PMHLRmZpn9P4XKNgNZGXciAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3012fe908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_true = b[7756:]\n",
    "cls_pred = sess.run(tf.argmax(hypothesis, 1), feed_dict=test_feed_dict)\n",
    "cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)        \n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(6)\n",
    "plt.xticks(tick_marks, range(6))\n",
    "plt.yticks(tick_marks, range(6))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Accuracy: 0.82663] 0\n",
      "[Accuracy: 0.80805] 1\n",
      "[Accuracy: 0.76852] 2\n",
      "[Accuracy: 0.83591] 3\n",
      "[Accuracy: 0.87926] 4\n",
      "[Accuracy: 0.92901] 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(\"[Accuracy: {:>.5f}] {}\".format(cm[i][i] / d[i], c[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
