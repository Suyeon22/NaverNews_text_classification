{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DBOW_model = doc2vec.Doc2Vec.load('DBOW_model4.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "with open('test.txt', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "tagged_train = [TaggedDocument(d, [c]) for d, c in train]\n",
    "tagged_test = [TaggedDocument(d, [c]) for d, c in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. 모델 테스트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류를 위해 tagged_train과 tagged_test의 words와 tags를 나눠줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [DBOW_model.infer_vector(doc.words) for doc in tagged_train]\n",
    "y_train = [doc.tags[0] for doc in tagged_train]\n",
    "len(X_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [DBOW_model.infer_vector(doc.words) for doc in tagged_test]\n",
    "y_test = [doc.tags[0] for doc in tagged_test]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeling = y_train+y_test\n",
    "labeling_np = np.asarray(labeling, dtype=str)\n",
    "\n",
    "a , b = np.unique(labeling_np, return_inverse=True ) # 0~7755\n",
    "c , d = np.unique(labeling_np[7756:], return_counts=True )\n",
    "\n",
    "train_label_np=a[b][:7756]\n",
    "test_label_np=a[b][7756:]\n",
    "\n",
    "y_train_np=b[:7756].astype(int)\n",
    "y_test_np=b[7756:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '3', '2', ..., '2', '2', '5'], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 6\n",
    "y_train_np = np.eye(nb_classes)[y_train_np]\n",
    "y_test_np = np.eye(nb_classes)[y_test_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with MLP : [해당 자료 참고](https://gitlab.com/agilesoda/Word2Vec/blob/master/03_Word2Vec_Gensim.ipynb)하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hufs/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/hufs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout, variance_scaling_initializer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "keep_prob = 0.5\n",
    "He = variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7756, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 300])\n",
    "Y = tf.placeholder(tf.float32, [None, 6])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected]):\n",
    "    \n",
    "    hidden_layer1 = fully_connected(X, 512, scope=\"h1\", weights_initializer=He)\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer2 = fully_connected(h1_drop, 512, scope=\"h2\", weights_initializer=He)\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer3 = fully_connected(h2_drop, 1024, scope=\"h3\", weights_initializer=He)\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer4 = fully_connected(h3_drop, 1024, scope=\"h4\", weights_initializer=He)\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hypothesis = fully_connected(h4_drop, 6, activation_fn=None, scope=\"hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "\n",
    "# AdamOptimizer 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"train_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy)\n",
    "\n",
    "with tf.name_scope(\"test_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_acc\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# summary 노드 : 모든 요약 데이터를 실행하는 단일 연산(op)으로 결합\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# 마지막으로 이 요약 데이터를 save하기 위해 tf.summary.FileWriter로 전달한다.\n",
    "writer = tf.summary.FileWriter(\"./logs/DBOW4\")\n",
    "\n",
    "# Show the graph\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> command 창에서 다음을 입력하고 tensorboard를 실행한다\n",
    "*  tensorboard --logdir=./logs/naver_classificaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    0][Train: 0.77627][Test: 0.84227][2018-01-29 16:14:04]\n",
      "[Epoch:    1][Train: 0.94108][Test: 0.86907][2018-01-29 16:14:07]\n",
      "[Epoch:    2][Train: 0.96192][Test: 0.87371][2018-01-29 16:14:10]\n",
      "[Epoch:    3][Train: 0.96874][Test: 0.87010][2018-01-29 16:14:13]\n",
      "[Epoch:    4][Train: 0.97756][Test: 0.87165][2018-01-29 16:14:16]\n",
      "[Epoch:    5][Train: 0.98220][Test: 0.87784][2018-01-29 16:14:18]\n",
      "[Epoch:    6][Train: 0.98550][Test: 0.87165][2018-01-29 16:14:21]\n",
      "[Epoch:    7][Train: 0.98997][Test: 0.86907][2018-01-29 16:14:23]\n",
      "[Epoch:    8][Train: 0.99379][Test: 0.86856][2018-01-29 16:14:26]\n",
      "[Epoch:    9][Train: 0.99661][Test: 0.86804][2018-01-29 16:14:28]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_acc = 0\n",
    "    total_batch = int(len(X_train_np) / batch_size)\n",
    "\n",
    "    for i in range(0, len(X_train_np), batch_size):\n",
    "        batch_xs = X_train_np[i:i+batch_size]\n",
    "        batch_ys = y_train_np[i:i+batch_size]\n",
    "        \n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_acc = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        acc = sess.run(train_accuracy, feed_dict=feed_dict_acc)\n",
    "        avg_acc += acc / total_batch\n",
    "        \n",
    "    test_feed_dict = {X: X_test_np, Y: y_test_np, train_mode: False}\n",
    "    summary, test_acc = sess.run([merged_summary, test_accuracy], feed_dict=test_feed_dict)\n",
    "    writer.add_summary(summary, global_step=epoch)      \n",
    "        \n",
    "#     if epoch % 10 == 0:\n",
    "    time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"[Epoch: {:>4}][Train: {:>.5f}][Test: {:>.5f}][{}]\".format(epoch, avg_acc, test_acc, time))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1)), tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(hypothesis,tf.argmax(Y, 1), k=2), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.99661 \n",
      " Test Accuracy: 0.86804 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {:>.5f} \\n Test Accuracy: {:>.5f} \\n\".format(avg_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 6])\n",
    "y_pred = tf.placeholder(tf.float32, [None, 6])\n",
    "y_true_cls = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.305,0.5,'True')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEmCAYAAAAjsVjMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzEFrZpaZg9bMLDMHrZlZZv8P49kOtuVzWkMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f18da52d400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_true = b[7756:]\n",
    "cls_pred = sess.run(tf.argmax(hypothesis, 1), feed_dict=test_feed_dict)\n",
    "cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)        \n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(6)\n",
    "plt.xticks(tick_marks, range(6))\n",
    "plt.yticks(tick_marks, range(6))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Accuracy: 0.91022] 0\n",
      "[Accuracy: 0.85139] 1\n",
      "[Accuracy: 0.79938] 2\n",
      "[Accuracy: 0.82353] 3\n",
      "[Accuracy: 0.88545] 4\n",
      "[Accuracy: 0.93827] 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(\"[Accuracy: {:>.5f}] {}\".format(cm[i][i] / d[i], c[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
