{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DM_model = doc2vec.Doc2Vec.load('DM_model2.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "with open('test.txt', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "tagged_train = [TaggedDocument(d, [c]) for d, c in train]\n",
    "tagged_test = [TaggedDocument(d, [c]) for d, c in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. 모델 테스트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류를 위해 tagged_train과 tagged_test의 words와 tags를 나눠줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [DM_model.infer_vector(doc.words) for doc in tagged_train]\n",
    "y_train = [doc.tags[0] for doc in tagged_train]\n",
    "len(X_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [DM_model.infer_vector(doc.words) for doc in tagged_test]\n",
    "y_test = [doc.tags[0] for doc in tagged_test]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeling = y_train+y_test\n",
    "labeling_np = np.asarray(labeling, dtype=str)\n",
    "\n",
    "a , b = np.unique(labeling_np, return_inverse=True ) # 0~7755\n",
    "c , d = np.unique(labeling_np[7756:], return_counts=True )\n",
    "\n",
    "train_label_np=a[b][:7756]\n",
    "test_label_np=a[b][7756:]\n",
    "\n",
    "y_train_np=b[:7756].astype(int)\n",
    "y_test_np=b[7756:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '3', '2', ..., '2', '2', '5'], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 6\n",
    "y_train_np = np.eye(nb_classes)[y_train_np]\n",
    "y_test_np = np.eye(nb_classes)[y_test_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with MLP : [해당 자료 참고](https://gitlab.com/agilesoda/Word2Vec/blob/master/03_Word2Vec_Gensim.ipynb)하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hufs/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/hufs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout, variance_scaling_initializer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "keep_prob = 0.5\n",
    "He = variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7756, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 100])\n",
    "Y = tf.placeholder(tf.float32, [None, 6])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected]):\n",
    "    \n",
    "    hidden_layer1 = fully_connected(X, 512, scope=\"h1\", weights_initializer=He)\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer2 = fully_connected(h1_drop, 512, scope=\"h2\", weights_initializer=He)\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer3 = fully_connected(h2_drop, 1024, scope=\"h3\", weights_initializer=He)\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer4 = fully_connected(h3_drop, 1024, scope=\"h4\", weights_initializer=He)\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hypothesis = fully_connected(h4_drop, 6, activation_fn=None, scope=\"hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "\n",
    "# AdamOptimizer 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"train_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy)\n",
    "\n",
    "with tf.name_scope(\"test_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_acc\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# summary 노드 : 모든 요약 데이터를 실행하는 단일 연산(op)으로 결합\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# 마지막으로 이 요약 데이터를 save하기 위해 tf.summary.FileWriter로 전달한다.\n",
    "writer = tf.summary.FileWriter(\"./logs/DM2\")\n",
    "\n",
    "# Show the graph\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> command 창에서 다음을 입력하고 tensorboard를 실행한다\n",
    "*  tensorboard --logdir=./logs/naver_classificaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    0][Train: 0.88172][Test: 0.83144][2018-01-29 16:23:52]\n",
      "[Epoch:    1][Train: 0.95554][Test: 0.83402][2018-01-29 16:23:55]\n",
      "[Epoch:    2][Train: 0.96210][Test: 0.84072][2018-01-29 16:23:58]\n",
      "[Epoch:    3][Train: 0.96705][Test: 0.84021][2018-01-29 16:24:01]\n",
      "[Epoch:    4][Train: 0.96657][Test: 0.83505][2018-01-29 16:24:04]\n",
      "[Epoch:    5][Train: 0.96917][Test: 0.83505][2018-01-29 16:24:06]\n",
      "[Epoch:    6][Train: 0.97148][Test: 0.83557][2018-01-29 16:24:09]\n",
      "[Epoch:    7][Train: 0.97248][Test: 0.83969][2018-01-29 16:24:12]\n",
      "[Epoch:    8][Train: 0.97343][Test: 0.83969][2018-01-29 16:24:14]\n",
      "[Epoch:    9][Train: 0.97317][Test: 0.83557][2018-01-29 16:24:17]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_acc = 0\n",
    "    total_batch = int(len(X_train_np) / batch_size)\n",
    "\n",
    "    for i in range(0, len(X_train_np), batch_size):\n",
    "        batch_xs = X_train_np[i:i+batch_size]\n",
    "        batch_ys = y_train_np[i:i+batch_size]\n",
    "        \n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_acc = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        acc = sess.run(train_accuracy, feed_dict=feed_dict_acc)\n",
    "        avg_acc += acc / total_batch\n",
    "        \n",
    "    test_feed_dict = {X: X_test_np, Y: y_test_np, train_mode: False}\n",
    "    summary, test_acc = sess.run([merged_summary, test_accuracy], feed_dict=test_feed_dict)\n",
    "    writer.add_summary(summary, global_step=epoch)      \n",
    "        \n",
    "#     if epoch % 10 == 0:\n",
    "    time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"[Epoch: {:>4}][Train: {:>.5f}][Test: {:>.5f}][{}]\".format(epoch, avg_acc, test_acc, time))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1)), tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(hypothesis,tf.argmax(Y, 1), k=2), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.97317 \n",
      " Test Accuracy: 0.83557 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {:>.5f} \\n Test Accuracy: {:>.5f} \\n\".format(avg_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 6])\n",
    "y_pred = tf.placeholder(tf.float32, [None, 6])\n",
    "y_true_cls = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.305,0.5,'True')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEmCAYAAAAjsVjMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7P8DKTWeaQuImp8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbffdbcee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_true = b[7756:]\n",
    "cls_pred = sess.run(tf.argmax(hypothesis, 1), feed_dict=test_feed_dict)\n",
    "cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)        \n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(6)\n",
    "plt.xticks(tick_marks, range(6))\n",
    "plt.yticks(tick_marks, range(6))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Accuracy: 0.83282] 0\n",
      "[Accuracy: 0.79876] 1\n",
      "[Accuracy: 0.76543] 2\n",
      "[Accuracy: 0.80495] 3\n",
      "[Accuracy: 0.89164] 4\n",
      "[Accuracy: 0.91975] 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(\"[Accuracy: {:>.5f}] {}\".format(cm[i][i] / d[i], c[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
