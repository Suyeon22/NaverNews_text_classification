{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DM_model = doc2vec.Doc2Vec.load('DM_model5.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "with open('test.txt', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "tagged_train = [TaggedDocument(d, [c]) for d, c in train]\n",
    "tagged_test = [TaggedDocument(d, [c]) for d, c in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. 모델 테스트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류를 위해 tagged_train과 tagged_test의 words와 tags를 나눠줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [DM_model.infer_vector(doc.words) for doc in tagged_train]\n",
    "y_train = [doc.tags[0] for doc in tagged_train]\n",
    "len(X_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [DM_model.infer_vector(doc.words) for doc in tagged_test]\n",
    "y_test = [doc.tags[0] for doc in tagged_test]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeling = y_train+y_test\n",
    "labeling_np = np.asarray(labeling, dtype=str)\n",
    "\n",
    "a , b = np.unique(labeling_np, return_inverse=True ) # 0~7755\n",
    "c , d = np.unique(labeling_np[7756:], return_counts=True )\n",
    "\n",
    "train_label_np=a[b][:7756]\n",
    "test_label_np=a[b][7756:]\n",
    "\n",
    "y_train_np=b[:7756].astype(int)\n",
    "y_test_np=b[7756:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '3', '2', ..., '2', '2', '5'], dtype='<U1')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 6\n",
    "y_train_np = np.eye(nb_classes)[y_train_np]\n",
    "y_test_np = np.eye(nb_classes)[y_test_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with MLP : [해당 자료 참고](https://gitlab.com/agilesoda/Word2Vec/blob/master/03_Word2Vec_Gensim.ipynb)하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout, variance_scaling_initializer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "keep_prob = 0.5\n",
    "He = variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7756, 300)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 300])\n",
    "Y = tf.placeholder(tf.float32, [None, 6])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected]):\n",
    "    \n",
    "    hidden_layer1 = fully_connected(X, 512, scope=\"h1\", weights_initializer=He)\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer2 = fully_connected(h1_drop, 512, scope=\"h2\", weights_initializer=He)\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer3 = fully_connected(h2_drop, 1024, scope=\"h3\", weights_initializer=He)\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer4 = fully_connected(h3_drop, 1024, scope=\"h4\", weights_initializer=He)\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hypothesis = fully_connected(h4_drop, 6, activation_fn=None, scope=\"hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "\n",
    "# AdamOptimizer 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"train_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy)\n",
    "\n",
    "with tf.name_scope(\"test_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_acc\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# summary 노드 : 모든 요약 데이터를 실행하는 단일 연산(op)으로 결합\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# 마지막으로 이 요약 데이터를 save하기 위해 tf.summary.FileWriter로 전달한다.\n",
    "writer = tf.summary.FileWriter(\"./logs/DM5\")\n",
    "\n",
    "# Show the graph\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> command 창에서 다음을 입력하고 tensorboard를 실행한다\n",
    "*  tensorboard --logdir=./logs/naver_classificaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    0][Train: 0.89188][Test: 0.82474][2018-01-29 16:24:29]\n",
      "[Epoch:    1][Train: 0.95759][Test: 0.83299][2018-01-29 16:24:31]\n",
      "[Epoch:    2][Train: 0.96154][Test: 0.83041][2018-01-29 16:24:33]\n",
      "[Epoch:    3][Train: 0.96571][Test: 0.83402][2018-01-29 16:24:36]\n",
      "[Epoch:    4][Train: 0.96662][Test: 0.83608][2018-01-29 16:24:39]\n",
      "[Epoch:    5][Train: 0.96935][Test: 0.83351][2018-01-29 16:24:42]\n",
      "[Epoch:    6][Train: 0.97066][Test: 0.82835][2018-01-29 16:24:44]\n",
      "[Epoch:    7][Train: 0.97092][Test: 0.84072][2018-01-29 16:24:47]\n",
      "[Epoch:    8][Train: 0.97018][Test: 0.83402][2018-01-29 16:24:49]\n",
      "[Epoch:    9][Train: 0.97235][Test: 0.83866][2018-01-29 16:24:52]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_acc = 0\n",
    "    total_batch = int(len(X_train_np) / batch_size)\n",
    "\n",
    "    for i in range(0, len(X_train_np), batch_size):\n",
    "        batch_xs = X_train_np[i:i+batch_size]\n",
    "        batch_ys = y_train_np[i:i+batch_size]\n",
    "        \n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_acc = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        acc = sess.run(train_accuracy, feed_dict=feed_dict_acc)\n",
    "        avg_acc += acc / total_batch\n",
    "        \n",
    "    test_feed_dict = {X: X_test_np, Y: y_test_np, train_mode: False}\n",
    "    summary, test_acc = sess.run([merged_summary, test_accuracy], feed_dict=test_feed_dict)\n",
    "    writer.add_summary(summary, global_step=epoch)      \n",
    "        \n",
    "#     if epoch % 10 == 0:\n",
    "    time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"[Epoch: {:>4}][Train: {:>.5f}][Test: {:>.5f}][{}]\".format(epoch, avg_acc, test_acc, time))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1)), tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(hypothesis,tf.argmax(Y, 1), k=2), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.97235 \n",
      " Test Accuracy: 0.83866 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {:>.5f} \\n Test Accuracy: {:>.5f} \\n\".format(avg_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 6])\n",
    "y_pred = tf.placeholder(tf.float32, [None, 6])\n",
    "y_true_cls = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.305,0.5,'True')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEmCAYAAAAjsVjMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzKCVpJ4ZtJLUM4NWknr2/wFBVoBeYA6DhgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f65e1aa7978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_true = b[7756:]\n",
    "cls_pred = sess.run(tf.argmax(hypothesis, 1), feed_dict=test_feed_dict)\n",
    "cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)        \n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(6)\n",
    "plt.xticks(tick_marks, range(6))\n",
    "plt.yticks(tick_marks, range(6))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Accuracy: 0.84830] 0\n",
      "[Accuracy: 0.82043] 1\n",
      "[Accuracy: 0.77469] 2\n",
      "[Accuracy: 0.78019] 3\n",
      "[Accuracy: 0.91022] 4\n",
      "[Accuracy: 0.89815] 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(\"[Accuracy: {:>.5f}] {}\".format(cm[i][i] / d[i], c[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
