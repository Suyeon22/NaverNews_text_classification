{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DBOW_model = doc2vec.Doc2Vec.load('DBOW_model6.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "with open('test.txt', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "tagged_train = [TaggedDocument(d, [c]) for d, c in train]\n",
    "tagged_test = [TaggedDocument(d, [c]) for d, c in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. 모델 테스트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류를 위해 tagged_train과 tagged_test의 words와 tags를 나눠줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [DBOW_model.infer_vector(doc.words) for doc in tagged_train]\n",
    "y_train = [doc.tags[0] for doc in tagged_train]\n",
    "len(X_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [DBOW_model.infer_vector(doc.words) for doc in tagged_test]\n",
    "y_test = [doc.tags[0] for doc in tagged_test]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeling = y_train+y_test\n",
    "labeling_np = np.asarray(labeling, dtype=str)\n",
    "\n",
    "a , b = np.unique(labeling_np, return_inverse=True ) # 0~7755\n",
    "c , d = np.unique(labeling_np[7756:], return_counts=True )\n",
    "\n",
    "train_label_np=a[b][:7756]\n",
    "test_label_np=a[b][7756:]\n",
    "\n",
    "y_train_np=b[:7756].astype(int)\n",
    "y_test_np=b[7756:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '3', '2', ..., '2', '2', '5'], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 6\n",
    "y_train_np = np.eye(nb_classes)[y_train_np]\n",
    "y_test_np = np.eye(nb_classes)[y_test_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with MLP : [해당 자료 참고](https://gitlab.com/agilesoda/Word2Vec/blob/master/03_Word2Vec_Gensim.ipynb)하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hufs/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/hufs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout, variance_scaling_initializer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "keep_prob = 0.5\n",
    "He = variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7756, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 300])\n",
    "Y = tf.placeholder(tf.float32, [None, 6])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected]):\n",
    "    \n",
    "    hidden_layer1 = fully_connected(X, 512, scope=\"h1\", weights_initializer=He)\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer2 = fully_connected(h1_drop, 512, scope=\"h2\", weights_initializer=He)\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer3 = fully_connected(h2_drop, 1024, scope=\"h3\", weights_initializer=He)\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer4 = fully_connected(h3_drop, 1024, scope=\"h4\", weights_initializer=He)\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hypothesis = fully_connected(h4_drop, 6, activation_fn=None, scope=\"hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "\n",
    "# AdamOptimizer 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"train_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy)\n",
    "\n",
    "with tf.name_scope(\"test_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_acc\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# summary 노드 : 모든 요약 데이터를 실행하는 단일 연산(op)으로 결합\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# 마지막으로 이 요약 데이터를 save하기 위해 tf.summary.FileWriter로 전달한다.\n",
    "writer = tf.summary.FileWriter(\"./logs/DBOW6\")\n",
    "\n",
    "# Show the graph\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> command 창에서 다음을 입력하고 tensorboard를 실행한다\n",
    "*  tensorboard --logdir=./logs/naver_classificaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    0][Train: 0.62495][Test: 0.74278][2018-01-29 16:15:52]\n",
      "[Epoch:    1][Train: 0.85970][Test: 0.83041][2018-01-29 16:15:57]\n",
      "[Epoch:    2][Train: 0.92130][Test: 0.85155][2018-01-29 16:16:02]\n",
      "[Epoch:    3][Train: 0.94492][Test: 0.85722][2018-01-29 16:16:07]\n",
      "[Epoch:    4][Train: 0.95981][Test: 0.85825][2018-01-29 16:16:12]\n",
      "[Epoch:    5][Train: 0.96875][Test: 0.85670][2018-01-29 16:16:18]\n",
      "[Epoch:    6][Train: 0.97773][Test: 0.85567][2018-01-29 16:16:26]\n",
      "[Epoch:    7][Train: 0.98164][Test: 0.86134][2018-01-29 16:16:33]\n",
      "[Epoch:    8][Train: 0.98997][Test: 0.85670][2018-01-29 16:16:39]\n",
      "[Epoch:    9][Train: 0.99648][Test: 0.85773][2018-01-29 16:16:45]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_acc = 0\n",
    "    total_batch = int(len(X_train_np) / batch_size)\n",
    "\n",
    "    for i in range(0, len(X_train_np), batch_size):\n",
    "        batch_xs = X_train_np[i:i+batch_size]\n",
    "        batch_ys = y_train_np[i:i+batch_size]\n",
    "        \n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_acc = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        acc = sess.run(train_accuracy, feed_dict=feed_dict_acc)\n",
    "        avg_acc += acc / total_batch\n",
    "        \n",
    "    test_feed_dict = {X: X_test_np, Y: y_test_np, train_mode: False}\n",
    "    summary, test_acc = sess.run([merged_summary, test_accuracy], feed_dict=test_feed_dict)\n",
    "    writer.add_summary(summary, global_step=epoch)      \n",
    "        \n",
    "#     if epoch % 10 == 0:\n",
    "    time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"[Epoch: {:>4}][Train: {:>.5f}][Test: {:>.5f}][{}]\".format(epoch, avg_acc, test_acc, time))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1)), tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(hypothesis,tf.argmax(Y, 1), k=2), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.99648 \n",
      " Test Accuracy: 0.85773 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {:>.5f} \\n Test Accuracy: {:>.5f} \\n\".format(avg_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 6])\n",
    "y_pred = tf.placeholder(tf.float32, [None, 6])\n",
    "y_true_cls = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.305,0.5,'True')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEmCAYAAAAjsVjMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naAEgMYIWABL7f8/ks14D+dj5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe04095860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_true = b[7756:]\n",
    "cls_pred = sess.run(tf.argmax(hypothesis, 1), feed_dict=test_feed_dict)\n",
    "cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)        \n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(6)\n",
    "plt.xticks(tick_marks, range(6))\n",
    "plt.yticks(tick_marks, range(6))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Accuracy: 0.86068] 0\n",
      "[Accuracy: 0.85139] 1\n",
      "[Accuracy: 0.77778] 2\n",
      "[Accuracy: 0.83282] 3\n",
      "[Accuracy: 0.90402] 4\n",
      "[Accuracy: 0.91975] 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(\"[Accuracy: {:>.5f}] {}\".format(cm[i][i] / d[i], c[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
