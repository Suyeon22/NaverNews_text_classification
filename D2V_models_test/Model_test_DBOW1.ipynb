{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DBOW_model = doc2vec.Doc2Vec.load('DBOW_model1.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "with open('test.txt', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "\n",
    "tagged_train = [TaggedDocument(d, [c]) for d, c in train]\n",
    "tagged_test = [TaggedDocument(d, [c]) for d, c in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. 모델 테스트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류를 위해 tagged_train과 tagged_test의 words와 tags를 나눠줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [DBOW_model.infer_vector(doc.words) for doc in tagged_train]\n",
    "y_train = [doc.tags[0] for doc in tagged_train]\n",
    "len(X_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [DBOW_model.infer_vector(doc.words) for doc in tagged_test]\n",
    "y_test = [doc.tags[0] for doc in tagged_test]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeling = y_train+y_test\n",
    "labeling_np = np.asarray(labeling, dtype=str)\n",
    "\n",
    "a , b = np.unique(labeling_np, return_inverse=True ) # 0~7755\n",
    "c , d = np.unique(labeling_np[7756:], return_counts=True )\n",
    "\n",
    "train_label_np=a[b][:7756]\n",
    "test_label_np=a[b][7756:]\n",
    "\n",
    "y_train_np=b[:7756].astype(int)\n",
    "y_test_np=b[7756:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '3', '2', ..., '2', '2', '5'], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 6\n",
    "y_train_np = np.eye(nb_classes)[y_train_np]\n",
    "y_test_np = np.eye(nb_classes)[y_test_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with MLP : [해당 자료 참고](https://gitlab.com/agilesoda/Word2Vec/blob/master/03_Word2Vec_Gensim.ipynb)하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hufs/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/hufs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout, variance_scaling_initializer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "keep_prob = 0.5\n",
    "He = variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7756, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 100])\n",
    "Y = tf.placeholder(tf.float32, [None, 6])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected]):\n",
    "    \n",
    "    hidden_layer1 = fully_connected(X, 512, scope=\"h1\", weights_initializer=He)\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer2 = fully_connected(h1_drop, 512, scope=\"h2\", weights_initializer=He)\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer3 = fully_connected(h2_drop, 1024, scope=\"h3\", weights_initializer=He)\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer4 = fully_connected(h3_drop, 1024, scope=\"h4\", weights_initializer=He)\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hypothesis = fully_connected(h4_drop, 6, activation_fn=None, scope=\"hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "\n",
    "# AdamOptimizer 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"train_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy)\n",
    "\n",
    "with tf.name_scope(\"test_acc\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_acc\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# summary 노드 : 모든 요약 데이터를 실행하는 단일 연산(op)으로 결합\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# 마지막으로 이 요약 데이터를 save하기 위해 tf.summary.FileWriter로 전달한다.\n",
    "writer = tf.summary.FileWriter(\"./logs/DBOW1\")\n",
    "\n",
    "# Show the graph\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> command 창에서 다음을 입력하고 tensorboard를 실행한다\n",
    "*  tensorboard --logdir=./logs/naver_classificaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    0][Train: 0.74742][Test: 0.83557][2018-01-29 16:11:07]\n",
      "[Epoch:    1][Train: 0.92185][Test: 0.85876][2018-01-29 16:11:09]\n",
      "[Epoch:    2][Train: 0.94135][Test: 0.86546][2018-01-29 16:11:11]\n",
      "[Epoch:    3][Train: 0.95168][Test: 0.86907][2018-01-29 16:11:13]\n",
      "[Epoch:    4][Train: 0.96080][Test: 0.86907][2018-01-29 16:11:16]\n",
      "[Epoch:    5][Train: 0.97061][Test: 0.87423][2018-01-29 16:11:18]\n",
      "[Epoch:    6][Train: 0.97170][Test: 0.87732][2018-01-29 16:11:20]\n",
      "[Epoch:    7][Train: 0.97643][Test: 0.87010][2018-01-29 16:11:22]\n",
      "[Epoch:    8][Train: 0.97843][Test: 0.87784][2018-01-29 16:11:25]\n",
      "[Epoch:    9][Train: 0.98133][Test: 0.87680][2018-01-29 16:11:27]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_acc = 0\n",
    "    total_batch = int(len(X_train_np) / batch_size)\n",
    "\n",
    "    for i in range(0, len(X_train_np), batch_size):\n",
    "        batch_xs = X_train_np[i:i+batch_size]\n",
    "        batch_ys = y_train_np[i:i+batch_size]\n",
    "        \n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_acc = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        \n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        acc = sess.run(train_accuracy, feed_dict=feed_dict_acc)\n",
    "        avg_acc += acc / total_batch\n",
    "        \n",
    "    test_feed_dict = {X: X_test_np, Y: y_test_np, train_mode: False}\n",
    "    summary, test_acc = sess.run([merged_summary, test_accuracy], feed_dict=test_feed_dict)\n",
    "    writer.add_summary(summary, global_step=epoch)      \n",
    "        \n",
    "#     if epoch % 10 == 0:\n",
    "    time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"[Epoch: {:>4}][Train: {:>.5f}][Test: {:>.5f}][{}]\".format(epoch, avg_acc, test_acc, time))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1)), tf.float32))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(hypothesis,tf.argmax(Y, 1), k=2), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.98133 \n",
      " Test Accuracy: 0.87680 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {:>.5f} \\n Test Accuracy: {:>.5f} \\n\".format(avg_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, 6])\n",
    "y_pred = tf.placeholder(tf.float32, [None, 6])\n",
    "y_true_cls = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.305,0.5,'True')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEmCAYAAAAjsVjMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f39cffb1438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_true = b[7756:]\n",
    "cls_pred = sess.run(tf.argmax(hypothesis, 1), feed_dict=test_feed_dict)\n",
    "cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)        \n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(6)\n",
    "plt.xticks(tick_marks, range(6))\n",
    "plt.yticks(tick_marks, range(6))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Accuracy: 0.91022] 0\n",
      "[Accuracy: 0.84520] 1\n",
      "[Accuracy: 0.80864] 2\n",
      "[Accuracy: 0.84830] 3\n",
      "[Accuracy: 0.89783] 4\n",
      "[Accuracy: 0.95062] 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(\"[Accuracy: {:>.5f}] {}\".format(cm[i][i] / d[i], c[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
